From dda781f61cee5db904129f036c939cdfe72df4e2 Mon Sep 17 00:00:00 2001
From: Matt Madison <matt@madison.systems>
Date: Tue, 31 Aug 2021 04:32:37 -0700
Subject: [PATCH 7/9] trt_inference: use smart pointers during model
 conversions

instead of the old, deprecated style of using raw pointers
and calling the destroy methods of the various interfaces,
which is causing segfaults.
---
 .../common/algorithm/trt/trt_inference.cpp    | 33 ++++++-------------
 1 file changed, 10 insertions(+), 23 deletions(-)

diff --git a/samples/common/algorithm/trt/trt_inference.cpp b/samples/common/algorithm/trt/trt_inference.cpp
index 6b18cb7..4de44df 100644
--- a/samples/common/algorithm/trt/trt_inference.cpp
+++ b/samples/common/algorithm/trt/trt_inference.cpp
@@ -446,12 +446,12 @@ TRT_Context::caffeToTRTModel(const string& deployfile, const string& modelfile)
     Int8EntropyCalibrator calibrator;
     IInt8Calibrator* int8Calibrator = &calibrator;
     // create API root class - must span the lifetime of the engine usage
-    IBuilder *builder = createInferBuilder(*pLogger);
-    INetworkDefinition *network = builder->createNetworkV2(0U);
-    IBuilderConfig* config = builder->createBuilderConfig();
+    auto builder = std::unique_ptr<IBuilder>(createInferBuilder(*pLogger));
+    auto network = std::unique_ptr<INetworkDefinition>(builder->createNetworkV2(0U));
+    auto config = std::unique_ptr<IBuilderConfig>(builder->createBuilderConfig());
 
     // parse the caffe model to populate the network, then set the outputs
-    ICaffeParser *parser = createCaffeParser();
+    auto parser = std::unique_ptr<ICaffeParser>(createCaffeParser());
 
     bool hasFp16 = builder->platformHasFastFp16();
 
@@ -511,18 +511,11 @@ TRT_Context::caffeToTRTModel(const string& deployfile, const string& modelfile)
         config->setFlag(BuilderFlag::kFP16);
     }
 
-    ICudaEngine* engine = builder->buildEngineWithConfig(*network, *config);
+    auto engine = std::unique_ptr<ICudaEngine>(builder->buildEngineWithConfig(*network, *config));
     assert(engine);
 
-    // we don't need the network any more, and we can destroy the parser
-    network->destroy();
-    parser->destroy();
-    config->destroy();
-
     // serialize the engine, then close everything down
     trtModelStream = engine->serialize();
-    engine->destroy();
-    builder->destroy();
     shutdownProtobufLibrary();
 }
 
@@ -532,13 +525,13 @@ TRT_Context::onnxToTRTModel(const string& modelfile)
     Int8EntropyCalibrator calibrator(true, true);
     IInt8Calibrator* int8Calibrator = &calibrator;
     // create API root class - must span the lifetime of the engine usage
-    IBuilder *builder = createInferBuilder(*pLogger);
+    auto builder = std::unique_ptr<IBuilder>(createInferBuilder(*pLogger));
     const auto explicitBatch = 1U << static_cast<uint32_t>(NetworkDefinitionCreationFlag::kEXPLICIT_BATCH);
-    INetworkDefinition* network = builder->createNetworkV2(explicitBatch);
+    auto network = std::unique_ptr<INetworkDefinition>(builder->createNetworkV2(explicitBatch));
 
-    IBuilderConfig* config = builder->createBuilderConfig();
+    auto config = std::unique_ptr<IBuilderConfig>(builder->createBuilderConfig());
 
-    auto parser = nvonnxparser::createParser(*network, *pLogger);
+    auto parser = std::unique_ptr<IParser>(nvonnxparser::createParser(*network, *pLogger));
 
     bool hasFp16 = builder->platformHasFastFp16();
 
@@ -596,18 +589,12 @@ TRT_Context::onnxToTRTModel(const string& modelfile)
         config->setFlag(BuilderFlag::kFP16);
     }
 
-    ICudaEngine* engine = builder->buildEngineWithConfig(*network, *config);
+    auto engine = std::unique_ptr<ICudaEngine>(builder->buildEngineWithConfig(*network, *config));
     assert(engine);
 
-    // we don't need the network any more, and we can destroy the parser
-    network->destroy();
-    parser->destroy();
-    config->destroy();
 
     // serialize the engine, then close everything down
     trtModelStream = engine->serialize();
-    engine->destroy();
-    builder->destroy();
     shutdownProtobufLibrary();
 }
 
-- 
2.30.2

